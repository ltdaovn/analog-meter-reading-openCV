{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ltdaovn/analog-meter-reading-openCV/blob/main/test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tah2Tv4dsJWa"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "!pip install keras\n",
        "!pip install tensorflow  \n",
        "!pip3 install opencv-python\n",
        "!pip install pypng\n",
        "!pip install matplotlib\n",
        "\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "from skimage import data,filters\n",
        "from PIL import ImageTk, Image\n",
        "\n",
        "\n",
        "import cv2\n",
        "import csv\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.pylab as plt\n",
        "import matplotlib.cm as cm\n",
        "import numpy as np\n",
        "import pathlib\n",
        "import PIL\n",
        "import os,png,array\n",
        "import pandas as pd\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8j64_DxNedXL"
      },
      "source": [
        "!wget https://github.com/ltdaovn/analog-meter-reading-openCV/raw/main/cnn_svhn_.model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvEGCS6gnE_g"
      },
      "source": [
        "!wget \"https://github.com/ltdaovn/analog-meter-reading-openCV/raw/main/easy_samples.zip\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "si2arnOPnVYP",
        "outputId": "8a50a427-fd0d-4814-f7b7-d582ebbc9eb3"
      },
      "source": [
        "!unzip easy_samples.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  easy_samples.zip\n",
            "   creating: easy_samples/\n",
            "  inflating: easy_samples/1.png      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmYzoTvtsyIv",
        "outputId": "83c31f4a-1c07-46f0-db36-084b76256a95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "from keras.models import load_model\n",
        "classifier=load_model('cnn_svhn_.model')\n",
        "\n",
        "row_list = []\n",
        "index_counter = 0\n",
        "resize_counter = 0\n",
        "\n",
        "directory=\"easy_samples/\"\n",
        "\n",
        "for file in os.listdir(directory):\n",
        "  path = directory + file\n",
        "  print(path)\n",
        "  try:\n",
        "\n",
        "    if (file.endswith(\".jpg\") or file.endswith(\".png\")): \n",
        "        img = cv2.imread(path, 0)\n",
        "\n",
        "        if img is not None:\n",
        "            #blur = cv2.GaussianBlur(grey, value, 0)\n",
        "            img = cv2.GaussianBlur(img, (3,3), 0)\n",
        "\n",
        "        edges = cv2.Canny(img, 175, 200, apertureSize=3, L2gradient=False)\n",
        "        def auto_canny(image, sigma=0.33):\n",
        "\n",
        "            v = np.median(image)\n",
        "            lower = int(max(0, (1.0 - sigma) * v))\n",
        "            upper = int(min(255, (1.0 + sigma) * v))\n",
        "            edged = cv2.Canny(image, lower, upper, apertureSize=3, L2gradient=True)\n",
        "            return edged\n",
        "\n",
        "        #edges = auto_canny(img)\n",
        "\n",
        "        contours, hierarchy = cv2.findContours(edges.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "        contours_dict = dict()\n",
        "        for cont in contours:\n",
        "            x, y, w, h = cv2.boundingRect(cont)\n",
        "            area = cv2.contourArea(cont)\n",
        "            if 20 < area and 20 < w and h > 10 :\n",
        "                contours_dict[(x, y, w, h)] = cont\n",
        "\n",
        "        contours_filtered = sorted(contours_dict.values(), key=cv2.boundingRect)\n",
        "        blank_background = np.zeros_like(edges)\n",
        "        img_contours = cv2.drawContours(blank_background, contours_filtered, -1, (255,255,255), thickness=2)\n",
        "\n",
        "        def is_overlapping_horizontally(box1, box2):\n",
        "            x1, _, w1, _ = box1\n",
        "            x2, _, _, _ = box2\n",
        "            if x1 > x2:\n",
        "                return is_overlapping_horizontally(box2, box1)\n",
        "            return (x2 - x1) < w1\n",
        "\n",
        "        def merge(box1, box2):\n",
        "            assert is_overlapping_horizontally(box1, box2)\n",
        "            x1, y1, w1, h1 = box1\n",
        "            x2, y2, w2, h2 = box2\n",
        "            x = min(x1, x2)\n",
        "            w = max(x1 + w1, x2 + w2) - x\n",
        "            y = min(y1, y2)\n",
        "            h = max(y1 + h1, y2 + h2) - y\n",
        "            return (x, y, w, h)\n",
        "\n",
        "        def windows(contours):\n",
        "            boxes = []\n",
        "            for cont in contours:\n",
        "                box = cv2.boundingRect(cont)\n",
        "                if not boxes:\n",
        "                    boxes.append(box)\n",
        "                else:\n",
        "                    if is_overlapping_horizontally(boxes[-1], box):\n",
        "                        last_box = boxes.pop()\n",
        "                        merged_box = merge(box, last_box)\n",
        "                        boxes.append(merged_box)\n",
        "                    else:\n",
        "                        boxes.append(box)\n",
        "            return boxes\n",
        "\n",
        "        boxes = windows(contours_filtered)\n",
        "        len_boxes = len(boxes)\n",
        "\n",
        "        for n in range(len_boxes):\n",
        "          x, y, w, h = boxes[n]\n",
        "          plt.axis('off')\n",
        "          \n",
        "          if y < 10:\n",
        "              y = 10\n",
        "          if x < 10:\n",
        "              x = 10\n",
        "              \n",
        "          roi = img[y-10:y+h+5, x-10:x+w+5]\n",
        "          roi = cv2.resize(roi,(32, 32),interpolation = cv2.INTER_AREA)\n",
        "          a = str(n+1)\n",
        "          cv2.imwrite('basamak'+a+'.png', roi)\n",
        "\n",
        "        columnNames = list()\n",
        "\n",
        "        for i in range(1024):\n",
        "            pixel = 'pixel'\n",
        "            pixel += str(i)\n",
        "            columnNames.append(pixel)\n",
        "\n",
        "        train_data = pd.DataFrame(columns = columnNames)\n",
        "\n",
        "        for n in range(len_boxes):\n",
        "            a = str(n+1)\n",
        "            b='basamak'+a+'.png'\n",
        "            img = Image.open(b)\n",
        "            rawData = img.load()\n",
        "            data = []\n",
        "            for y in range(32):\n",
        "                for x in range(32):\n",
        "                    data.append(rawData[x,y])\n",
        "            k = 0\n",
        "            train_data.loc[0] = [data[k] for k in range(1024)]\n",
        "            train_data = train_data.div(255)\n",
        "            train_data.to_csv(\"train_converted\"+a+\".csv\",index = False)\n",
        "\n",
        "\n",
        "        w ={}\n",
        "        for n in range(len_boxes):\n",
        "            a = str(n+1)\n",
        "            b = \"train_converted\"+a+\".csv\"\n",
        "            x_pred = pd.read_csv(b)\n",
        "            x_pred = x_pred.iloc[:,:].values.astype('float32')\n",
        "            x_pred =x_pred.reshape(-1, 32, 32, 1)\n",
        "            predictions=classifier.predict(x_pred)\n",
        "            x = predictions[4]\n",
        "            c = \"predictions\"+a\n",
        "            w.update( {c : x.argmax()} )\n",
        "        \n",
        "        row = [file,  str(w.get(\"predictions1\")) + \n",
        "               str(w.get(\"predictions2\")) +  \n",
        "               str(w.get(\"predictions3\")) +\n",
        "               str(w.get(\"predictions4\")) +\n",
        "               str(w.get(\"predictions5\")) +\n",
        "               str(w.get(\"predictions6\")) ]\n",
        "\n",
        "        row_list.append(row)\n",
        "\n",
        "        print( file + \" \" + \"SAYAÇ MİKTAR: \" +\n",
        "            str(w.get(\"predictions1\")) + \n",
        "            str(w.get(\"predictions2\")) +  \n",
        "            str(w.get(\"predictions3\")) +\n",
        "            str(w.get(\"predictions4\")) +\n",
        "            str(w.get(\"predictions5\")) +\n",
        "            str(w.get(\"predictions6\")) \n",
        "            )\n",
        "\n",
        "        continue\n",
        "        \n",
        "    else:\n",
        "        continue\n",
        "\n",
        "  except IndexError:\n",
        "    if IndexError:\n",
        "      index_counter += 1\n",
        "      print(file + \" \" +'List index out of range error')\n",
        "      print('index count: ', index_counter)\n",
        "      pass\n",
        "\n",
        "  '''except:\n",
        "    row = [file, \"Resize Error\"]\n",
        "    resize_counter += 1\n",
        "    print('resize count: ', resize_counter)\n",
        "    print(file + \" \" + 'resize error')'''"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "easy_samples/1.png\n",
            "1.png SAYAÇ MİKTAR: 7NoneNoneNoneNoneNone\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAADnCAYAAAC9roUQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAADKUlEQVR4nO3UMQEAIAzAMMC/5+GiHCQKenXPzAKgcV4HAPzEdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIHQBcjcEy3+fc28AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8f_7HoCSu-p",
        "outputId": "bdffa1ba-c501-4e20-c33d-6361111db106"
      },
      "source": [
        "print(row_list)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3pqAMSVuNxE",
        "outputId": "e0488eb2-5a0f-47f9-ac0e-67efeda48c5e"
      },
      "source": [
        "# Create a file for new predicted values, then write it\n",
        "# update this csv each time you changed something in the code above \n",
        "# then follow these steps and calculate the accuracy, compare with other results\n",
        "with open('analog_predicted_meter.csv', 'w', newline='') as file:\n",
        "  writer = csv.writer(file)\n",
        "  writer.writerows(row_list)\n",
        "print(len(row_list))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSC3zXTPt_Lr",
        "outputId": "8462359c-b036-4532-861c-77abc32b26ae"
      },
      "source": [
        "print(\"-------------------------------------\")\n",
        "print(\"resize counter error:\", \" \", resize_counter)\n",
        "print(\"index counter error:\" , \" \" , index_counter)\n",
        "print(\"-------------------------------------\")\n",
        "read = 169 - (int(resize_counter) + int(index_counter))\n",
        "not_read = int(resize_counter) + int(index_counter)\n",
        "print(\"reading: \", read)\n",
        "print(\"not reading: \", not_read)\n",
        "print(\"-------------------------------------\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------\n",
            "resize counter error:   0\n",
            "index counter error:   0\n",
            "-------------------------------------\n",
            "reading:  169\n",
            "not reading:  0\n",
            "-------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "id": "8S4KwFn1wPtB",
        "outputId": "dfac2ad1-2f74-4b50-ebdb-9e80618383bd"
      },
      "source": [
        "read_value = pd.read_csv(\"analog_predicted_meter.csv\")\n",
        "read_value.columns = [\"imageID\", \"read_value\"]\n",
        "read_value[\"imageID\"] = read_value[\"imageID\"].str.replace(r'.jpg$', '')\n",
        "#read_val[\"ImageID\"] = read_val[\"ImageID\"].str.replace(r'.png$', '')\n",
        "\n",
        "# Delete basamak.png rows\n",
        "#read_val = read_val[read_val.ReadValue == basamak]\n",
        "\n",
        "read_value"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "EmptyDataError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mEmptyDataError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-07a735005b1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mread_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"analog_predicted_meter.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mread_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"imageID\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"read_value\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mread_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"imageID\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"imageID\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'.jpg$'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#read_val[\"ImageID\"] = read_val[\"ImageID\"].str.replace(r'.png$', '')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mEmptyDataError\u001b[0m: No columns to parse from file"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNGSRw3yxkiT"
      },
      "source": [
        "real_value = pd.read_excel(\"analog_actual_meter.xlsx\", dtype={'actual_value':np.str})\n",
        "real_value"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jp6hsBeEyyrA"
      },
      "source": [
        "merged = pd.merge(read_value, real_value, on=\"imageID\")\n",
        "%load_ext google.colab.data_table \n",
        "merged"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulUX9-TmEXZk"
      },
      "source": [
        "merged[\"read_value\"] = merged[\"read_value\"].str.replace(r'None', 'N')\n",
        "merged"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WafzNUwGzpTO"
      },
      "source": [
        "merged['IfMatch'] = np.where(merged['read_value'] == merged['actual_value'], 'True', 'False')\n",
        "merged[merged['IfMatch'] == 'True']\n",
        "#merged"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1ccNX3u_BdA"
      },
      "source": [
        "merged[\"Total\"] = merged['read_value'] \n",
        "\n",
        "for row in range(167):\n",
        "\n",
        "  match_counter = 0\n",
        "\n",
        "  for basamak in range(6):\n",
        "    if merged['read_value'][row][basamak]== merged['actual_value'][row][basamak]:\n",
        "      match_counter += 1\n",
        "\n",
        "  merged['Total'][row] = match_counter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYC877w-Ev_k"
      },
      "source": [
        "merged[\"digit_correctness_of_each_meter\"] = (merged[\"Total\"]/6)*100\n",
        " \n",
        "print(\"accuracy:\", (sum (merged[\"Total\"])/ (6*167))*100)\n",
        "\n",
        "merged"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}